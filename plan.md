plan.md
# MVP Feature Implementation Plan (Compliance Evidence Classifier)

**Overall Progress:** `82%`

> Scope strictly matches the PRD: upload evidence â†’ OCR parse (system, date) â†’ classify to framework control(s) â†’ persist & display. Future features (review/approval, progress tracking, reuse) are *out of scope* for this plan.

---

## Tasks

- [x] ğŸŸ© **Step 1: Repo & Environment Baseline**
  - [x] ğŸŸ© Confirm Supabase project keys and URLs via existing `.env.local` pattern; keep service-role key server-side only.
  - [x] ğŸŸ© Verify Supabase Auth is enabled for login in the Next.js app.
  - [x] ğŸŸ© Add minimal README notes for required env vars (Next + Python).

- [x] ğŸŸ© **Step 2: Database Schema Verification (No-Op if Present)**
  - [x] ğŸŸ© Verify existence of canonical tables: `frameworks`, `controls`, `mappings`, `mapping_references`.
  - [x] ğŸŸ© Verify operational tables: `audits`, `evidence` with required columns:
        - `evidence`: `id`, `audit_id`, `file_url`, `extracted_text`, `system`, `evidence_date`, `classification jsonb`, `status`, `uploaded_by`, `created_at`
  - [x] ğŸŸ© Validate constraints & indexes:
        - `frameworks (name, version)` unique
        - `controls.control_id` unique
        - `mappings (control_id, framework_id)` unique + FKs
        - Helpful indexes on `mappings.control_id`, `mappings.framework_id`
  - [x] ğŸŸ© If discrepancies found, apply **additive** migrations only (`ALTER TABLE ADD COLUMN`, `CREATE INDEX`). **No destructive changes.**
  - [x] ğŸŸ© Record schema check result (timestamp + schema version/hash) in a simple changelog note.

- [x] ğŸŸ© **Step 3: Frontend Upload UI (Next.js + Shadcn)**
  - [x] ğŸŸ© Build *Evidence Upload* form (single-file, drag/drop or file input).
  - [x] ğŸŸ© Upload file directly to **Supabase Storage** using a signed upload flow.
  - [x] ğŸŸ© After upload, POST metadata (audit id + storage path) to Python API to start processing.
  - [x] ğŸŸ© Show immediate â€œUploading â†’ Processingâ€ status.

- [ ] ğŸŸ¨ **Step 4: Python Service â€“ API Skeleton**
  - [x] ğŸŸ© Create minimal web service (FastAPI/Flask) with `/process-evidence` endpoint.
  - [x] ğŸŸ© Validate input (storage path, user, audit id); fetch file via signed URL or public URL.
  - [ ] ğŸŸ¥ Write initial `evidence` row (`status='processing'`).

- [ ] ğŸŸ¨ **Step 5: OCR & Parsing (System, Date)**
  - [x] ğŸŸ© Implement OCR module (provider per env) to extract raw text.
  - [x] ğŸŸ© Parse `system` (rule or lookup) and `evidence_date` (robust date parser).
  - [ ] ğŸŸ¥ Persist `extracted_text`, `system`, `evidence_date` back to `evidence`.

- [ ] ğŸŸ¨ **Step 6: Classification to Controls**
  - [x] ğŸŸ© Load canonical data (`frameworks`, `controls`, optional `mappings`) for label space.
  - [x] ğŸŸ© Classify evidence text â†’ candidate list of `{framework_id, control_id, (mapping_id?), confidence}`.
  - [ ] ğŸŸ¥ Save to `evidence.classification` JSON and set `status='classified'` (or `error` on failure).

- [x] ğŸŸ© **Step 7: Frontend Results Display**
  - [x] ğŸŸ© Add a simple *Evidence List* view for the current audit.
  - [x] ğŸŸ© Show each itemâ€™s `status` and, when available, top classification (framework â†’ control code/title + confidence).
  - [x] ğŸŸ© Provide basic error state messaging (OCR fail / low confidence).

- [x] ğŸŸ© **Step 8: Minimal Security & Ops**
  - [x] ğŸŸ© Ensure Python service uses server-side Supabase key; Next.js uses anon key only.
  - [x] ğŸŸ© Configure CORS narrowly for the frontend origin.
  - [x] ğŸŸ© Limit accepted file types/sizes at upload and server validation.

- [ ] ğŸŸ¨ **Step 9: Seeds & Sanity Checks**
  - [x] ğŸŸ© Seed a small canonical dataset (a few `frameworks`, `controls`, and `mappings`) for local testing.
  - [ ] ğŸŸ¥ Manual smoke test: upload â†’ processing â†’ classified â†’ list renders result.

- [ ] ğŸŸ¨ **Step 10: Minimal Test Harness (Now)**
  - [x] ğŸŸ© Python (pytest): unit tests for date/system parsing; classifier JSON contract; API contract for `/process-evidence` (with stubs/mocks).
  - [ ] ğŸŸ¥ Frontend (Vitest + RTL): upload form fires correct POST; evidence list renders status & top classification.
  - [ ] ğŸŸ¥ Schema probes: verify required tables/columns exist (no-op if already correct).
  - [x] ğŸŸ© Fixtures: tiny OCR text samples + micro seeds for frameworks/controls/mappings.

---

## Notes
- Eventing is **explicit call from frontend to Python** after upload (no webhooks/queues) to stay minimal.
- `classification` JSON stores IDs that point to canonical tables (future UI can dereference without schema changes).
- No review/approval, progress dashboards, or evidence reuse in this MVP plan.
